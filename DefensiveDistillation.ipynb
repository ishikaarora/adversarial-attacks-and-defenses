{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DefensiveDistillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishikaarora/pytorch-tutorials/blob/master/DefensiveDistillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSYrFqOUOD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "%matplotlib inline\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgFbkVh2WVgX",
        "colab_type": "code",
        "outputId": "c8ae02c2-5250-4f7d-8bd9-0fb7011409d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data', train = True,\n",
        "                                        download = True, transform= transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 4, shuffle = True, num_workers = 2)\n",
        "testset = torchvision.datasets.CIFAR10(root= './data',train = False, download = True,\n",
        "                                      transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = 1, shuffle = False, num_workers = 2 ) \n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRfHSaafWX1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 \n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mi_d0ZkWefV",
        "colab_type": "code",
        "outputId": "af388be3-3c16-4ed5-b499-64fc3e4795d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  cat   dog   cat   cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7enbtUxrXRKs",
        "colab_type": "text"
      },
      "source": [
        "### CNN Model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkNh9Yc3U878",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-iB0xLJXW8O",
        "colab_type": "text"
      },
      "source": [
        "### Loading pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHaVjfvpVsbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UzEsCW8Vun_",
        "colab_type": "code",
        "outputId": "1a3687ba-73e3-4e83-a2c1-71d7161868f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5No9gZdURY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "model.load_state_dict(torch.load(\"cifar10_76\"))\n",
        "model.eval()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D13PUnwAqJxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0.9\n",
        "N_EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utdkZnIKqGdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOlLmtO8WKT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(model,loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _,predicted = torch.max(outputs.data,1)\n",
        "            total+=labels.size(0)\n",
        "            correct+=(predicted==labels).sum().item()\n",
        "    return (correct/total)*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DTrjqDqRf14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygKiIl9XRgM7",
        "colab_type": "text"
      },
      "source": [
        "#### Original model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAPDdq3OXeNo",
        "colab_type": "code",
        "outputId": "40e0eb86-a2dc-45c3-be25-157842970cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "test_accuracy = calculate_accuracy(model,testloader)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-db03994eeadf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a33531b5c414>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ChOgyioaRE",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Meqc5yRoZYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn_kd(outputs, labels, teacher_outputs, params):\n",
        "    \"\"\"\n",
        "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
        "    \"Hyperparameters\": temperature and alpha\n",
        "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
        "    and student expects the input tensor to be log probabilities! See Issue #2\n",
        "    \"\"\"\n",
        "    alpha = params[\"alpha\"]\n",
        "    T = params[\"temperature\"]\n",
        "    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
        "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
        "              F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "\n",
        "    return KD_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPpA8S7zjkml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function: get [batch_idx, teacher_outputs] list by running teacher model once\n",
        "def fetch_teacher_outputs(teacher_model, dataloader, params):\n",
        "    # set teacher_model to evaluation mode\n",
        "    teacher_model.eval()\n",
        "    teacher_outputs = []\n",
        "    for i, (data_batch, labels_batch) in enumerate(dataloader):\n",
        "        if params[\"cuda\"]:\n",
        "            data_batch, labels_batch = data_batch.cuda(async=True), \\\n",
        "                                        labels_batch.cuda(async=True)\n",
        "#         data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n",
        "\n",
        "        output_teacher_batch = teacher_model(data_batch).data.cpu().numpy()\n",
        "        teacher_outputs.append(output_teacher_batch)\n",
        "\n",
        "    return teacher_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCJEts1JkY3b",
        "colab_type": "text"
      },
      "source": [
        "### Distillation Model functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwsn9K-dZ22U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining train_kd & train_and_evaluate_kd functions\n",
        "def train_kd(model, teacher_outputs, optimizer, loss_fn_kd, dataloader, params):\n",
        "    \"\"\"Train the model on `num_steps` batches\n",
        "    Args:\n",
        "        model: (torch.nn.Module) the neural network\n",
        "        optimizer: (torch.optim) optimizer for parameters of model\n",
        "        loss_fn_kd: \n",
        "        dataloader: \n",
        "        metrics: (dict) \n",
        "        params: (Params) hyperparameters\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    # teacher_model.eval()\n",
        "\n",
        "    # summary for current training loop and a running average object for loss\n",
        "#     summ = []\n",
        "#     loss_avg = utils.RunningAverage()\n",
        "    running_loss = 0.0\n",
        "  \n",
        "    # Use tqdm for progress bar\n",
        "    with tqdm(total=len(dataloader)) as t:\n",
        "        for i, (train_batch, labels_batch) in enumerate(dataloader):\n",
        "            # move to GPU if available\n",
        "            if params[\"cuda\"]:\n",
        "                train_batch, labels_batch = train_batch.cuda(async=True), \\\n",
        "                                            labels_batch.cuda(async=True)\n",
        "            # convert to torch Variables\n",
        "#             train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n",
        "\n",
        "            # compute model output, fetch teacher output, and compute KD loss\n",
        "            output_batch = model(train_batch)\n",
        "\n",
        "            # get one batch output from teacher_outputs list\n",
        "            output_teacher_batch = torch.from_numpy(teacher_outputs[i])\n",
        "            if params[\"cuda\"]:\n",
        "                output_teacher_batch = output_teacher_batch.cuda(async=True)\n",
        "#             output_teacher_batch = Variable(output_teacher_batch, requires_grad=False)\n",
        "\n",
        "            loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n",
        "\n",
        "            # clear previous gradients, compute gradients of all variables wrt loss\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # performs updates using calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Evaluate summaries only once in a while\n",
        "#             if i % params.save_summary_steps == 0:\n",
        "#                 # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
        "#                 output_batch = output_batch.data.cpu().numpy()\n",
        "#                 labels_batch = labels_batch.data.cpu().numpy()\n",
        "\n",
        "#                 # compute all metrics on this batch\n",
        "#                 summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
        "#                                  for metric in metrics}\n",
        "#                 summary_batch['loss'] = loss.data[0]\n",
        "#                 summ.append(summary_batch)\n",
        "\n",
        "            # update the average loss\n",
        "#             loss_avg.update(loss.data[0])\n",
        "\n",
        "#             t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
        "#             t.update()\n",
        "            \n",
        "            running_loss+=loss.item() \n",
        "            if i%100==99:\n",
        "              print(\".\",end='')\n",
        "\n",
        "\n",
        "#     # compute mean of all metrics in summary\n",
        "#     metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
        "#     metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
        "#     logging.info(\"- Train metrics: \" + metrics_string)\n",
        "\n",
        "    return running_loss\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUTuf8z4kjOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_evaluate_kd(model, teacher_model, train_dataloader, val_dataloader, optimizer,\n",
        "                       loss_fn_kd,restore_file=None):\n",
        "    \"\"\"Train the model and evaluate every epoch.\n",
        "    Args:\n",
        "        model: (torch.nn.Module) the neural network\n",
        "        params: (Params) hyperparameters\n",
        "        model_dir: (string) directory containing config, weights and log\n",
        "        restore_file: (string) - file to restore (without its extension .pth.tar)\n",
        "    \"\"\"\n",
        "    # reload weights from restore_file if specified\n",
        "#     if restore_file is not None:\n",
        "#         restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n",
        "#         logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "#         utils.load_checkpoint(restore_path, model, optimizer)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    # Tensorboard logger setup\n",
        "    # board_logger = utils.Board_Logger(os.path.join(model_dir, 'board_logs'))\n",
        "\n",
        "    # fetch teacher outputs using teacher_model under eval() mode\n",
        "    loading_start = time.time()\n",
        "    teacher_model.eval()\n",
        "    teacher_outputs = fetch_teacher_outputs(teacher_model, train_dataloader, params)\n",
        "    elapsed_time = math.ceil(time.time() - loading_start)\n",
        "#     logging.info(\"- Finished computing teacher outputs after {} secs..\".format(elapsed_time))\n",
        "\n",
        "    # learning rate schedulers for different models:\n",
        "#     if params.model_version == \"resnet18_distill\":\n",
        "#         scheduler = StepLR(optimizer, step_size=150, gamma=0.1)\n",
        "#     # for cnn models, num_epoch is always < 100, so it's intentionally not using scheduler here\n",
        "#     elif params.model_version == \"cnn_distill\": \n",
        "#         scheduler = StepLR(optimizer, step_size=100, gamma=0.2) \n",
        "\n",
        "    for epoch in range(params[\"num_epochs\"]):\n",
        "#         running_loss = 0.0\n",
        "        start = time.time()\n",
        "#         scheduler.step()\n",
        "\n",
        "        # Run one epoch\n",
        "#         logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
        "\n",
        "        # compute number of batches in one epoch (one full pass over the training set)\n",
        "        running_loss = train_kd(model, teacher_outputs, optimizer, loss_fn_kd, train_dataloader, params)\n",
        "\n",
        "        # Evaluate for one epoch on validation set\n",
        "#         val_metrics = evaluate_kd(model, val_dataloader, metrics, params)\n",
        "\n",
        "        train_acc = calculate_accuracy(model,trainloader)      \n",
        "        val_acc = calculate_accuracy(model,testloader)\n",
        "        is_best = val_acc>=best_val_acc\n",
        "      \n",
        "        time_taken = (time.time()-start)/60\n",
        "        print(\"\\nIteration: {0} | Time taken: {4} |  Loss: {1} | Training accuracy: {2}% | Test accuracy: {3}%\".format(epoch+1, running_loss, train_acc, val_acc,time_taken))\n",
        "\n",
        "        # Save weights\n",
        "#         utils.save_checkpoint({'epoch': epoch + 1,\n",
        "#                                'state_dict': model.state_dict(),\n",
        "#                                'optim_dict' : optimizer.state_dict()},\n",
        "#                                is_best=is_best,\n",
        "#                                checkpoint=model_dir)\n",
        "\n",
        "        # If best_eval, best_save_path\n",
        "        if is_best:\n",
        "#             logging.info(\"- Found new best accuracy\")\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            # Save best val metrics in a json file in the model directory\n",
        "#             best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
        "#             utils.save_dict_to_json(val_metrics, best_json_path)\n",
        "\n",
        "        # Save latest val metrics in a json file in the model directory\n",
        "#         last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
        "#         utils.save_dict_to_json(val_metrics, last_json_path)\n",
        "\n",
        "\n",
        "        # #============ TensorBoard logging: uncomment below to turn in on ============#\n",
        "        # # (1) Log the scalar values\n",
        "        # info = {\n",
        "        #     'val accuracy': val_acc\n",
        "        # }\n",
        "\n",
        "        # for tag, value in info.items():\n",
        "        #     board_logger.scalar_summary(tag, value, epoch+1)\n",
        "\n",
        "        # # (2) Log values and gradients of the parameters (histogram)\n",
        "        # for tag, value in model.named_parameters():\n",
        "        #     tag = tag.replace('.', '/')\n",
        "        #     board_logger.histo_summary(tag, value.data.cpu().numpy(), epoch+1)\n",
        "        #     # board_logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), epoch+1)\n",
        "    return best_val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOG4HIz8o01m",
        "colab_type": "text"
      },
      "source": [
        "### Train model with distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-DjPW67pXLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxg-yDjopBgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "teacher_model = copy.deepcopy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY1NAKEVso9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = CNN()\n",
        "new_model = new_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI5iZRUmNH1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    \"alpha\": 0.9,\n",
        "    \"temperature\": 20,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"num_epochs\": 10,\n",
        "    \"cuda\": True\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-hV3o3UNMB9",
        "colab_type": "text"
      },
      "source": [
        "#### Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYskK_2HN8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "#     \"model_version\": \"cnn_distill\",\n",
        "#     \"subset_percent\": 1.0,\n",
        "#     \"augmentation\": \"yes\",\n",
        "#     \"teacher\": \"resnet18\",\n",
        "    \"alpha\": 0.9,\n",
        "    \"temperature\": 20,\n",
        "    \"learning_rate\": 0.001,\n",
        "#     \"batch_size\": 128,\n",
        "    \"num_epochs\": 10,\n",
        "#     \"dropout_rate\": 0.5, \n",
        "#     \"num_channels\": 32,\n",
        "#     \"save_summary_steps\": 100,\n",
        "#     \"num_workers\": 4\n",
        "    \"cuda\": True\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPf4iH_3H3Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# {\n",
        "#     \"model_version\": \"cnn\",\n",
        "#     \"subset_percent\": 1.0,\n",
        "#     \"augmentation\": \"no\",\n",
        "#     \"teacher\": \"none\",\n",
        "#     \"alpha\": 0,\n",
        "#     \"temperature\": 1,\n",
        "#     \"learning_rate\": 1e-3,\n",
        "#     \"batch_size\": 128,\n",
        "#     \"num_epochs\": 30,\n",
        "#     \"dropout_rate\": 0.5, \n",
        "#     \"num_channels\": 32,\n",
        "#     \"save_summary_steps\": 100,\n",
        "#     \"num_workers\": 4\n",
        "# }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8jAoMbeMNEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0dfb421c-7b54-4e7a-8ca9-693595a476c2"
      },
      "source": [
        "params"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.9,\n",
              " 'cuda': True,\n",
              " 'learning_rate': 0.001,\n",
              " 'num_epochs': 10,\n",
              " 'temperature': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d2Z1AuANQUt",
        "colab_type": "text"
      },
      "source": [
        "### New Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bROAcUUko0Xl",
        "colab_type": "code",
        "outputId": "1b28dc20-9a8b-4f5a-d902-171e1f8bd131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        }
      },
      "source": [
        "# params = {temperature=20.0, alpha=0.7}\n",
        "new_model_accuracy = train_and_evaluate_kd(new_model, teacher_model, trainloader, testloader, optimizer, loss_fn_kd,\n",
        "                              params)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12500 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1992: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 1 | Time taken: 4.36537564198176 |  Loss: 38358.67885234952 | Training accuracy: 10.126% | Test accuracy: 10.08%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 2 | Time taken: 4.255859382947286 |  Loss: 38359.17667546868 | Training accuracy: 10.108% | Test accuracy: 10.059999999999999%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 3 | Time taken: 4.364721135298411 |  Loss: 38359.22136411071 | Training accuracy: 10.204% | Test accuracy: 10.09%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 4 | Time taken: 4.295168300469716 |  Loss: 38358.70492297411 | Training accuracy: 10.122% | Test accuracy: 10.02%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 5 | Time taken: 4.33351970911026 |  Loss: 38359.19701638818 | Training accuracy: 10.142% | Test accuracy: 10.02%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 6 | Time taken: 4.29356453816096 |  Loss: 38359.15775182843 | Training accuracy: 10.144% | Test accuracy: 10.059999999999999%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 7 | Time taken: 4.343990488847097 |  Loss: 38359.221140027046 | Training accuracy: 10.156% | Test accuracy: 10.08%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 8 | Time taken: 4.244445927937826 |  Loss: 38359.518808960915 | Training accuracy: 10.106% | Test accuracy: 10.02%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 9 | Time taken: 4.32000135978063 |  Loss: 38358.9010630548 | Training accuracy: 10.094% | Test accuracy: 10.040000000000001%\n",
            "............................................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 10 | Time taken: 4.3317839940389 |  Loss: 38359.007610052824 | Training accuracy: 10.162% | Test accuracy: 10.100000000000001%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-6fa8f9392759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m new_model_accuracy = train_and_evaluate_kd(new_model, teacher_model, trainloader, testloader, optimizer, loss_fn_kd,\n\u001b[0;32m----> 2\u001b[0;31m                               params)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-9e19fcd42ddf>\u001b[0m in \u001b[0;36mtrain_and_evaluate_kd\u001b[0;34m(model, teacher_model, train_dataloader, val_dataloader, optimizer, loss_fn_kd, restore_file)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m#     board_logger.histo_summary(tag, value.data.cpu().numpy(), epoch+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m#     # board_logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), epoch+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_val_accuracy' is not defined"
          ]
        }
      ]
    }
  ]
}