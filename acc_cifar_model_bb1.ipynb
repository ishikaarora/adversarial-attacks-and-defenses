{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "acc_cifar_model_bb1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTEPIiF55euW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from PIL import Image\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMbf8mrE5lN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyJhtrvd5t4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10_mean = [0.49139968 , 0.48215841 , 0.44653091]\n",
        "cifar10_std = [0.24703223,  0.24348513 , 0.26158784]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCd71qqA51Iu",
        "colab_type": "code",
        "outputId": "84a38eb4-a16c-4054-c84b-816e296c095c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean,cifar10_std)\n",
        "])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform= transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J47sw8dchJ2_",
        "colab_type": "code",
        "outputId": "88501980-899d-47d4-ccb6-0c325327e162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiVb5CFH6HKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mymodel(nn.Module):\n",
        "    \"\"\"Custom Model\"\"\"\n",
        "\n",
        "    def __init__(self, in_features, hidden_dim, n_classes):\n",
        "        \"\"\"Custom Model Builder.\"\"\"\n",
        "        super(mymodel, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
        "        self.fc3 = nn.Linear(hidden_dim//2, n_classes)\n",
        "   \n",
        "  \n",
        "    def forward(self, images):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        images_vec = images.view(images.size(0), -1)\n",
        "        hidden_out = F.relu(self.fc1(images_vec))\n",
        "        hidden_out = F.relu(self.fc2(hidden_out))\n",
        "        scores = self.fc3(hidden_out)\n",
        "\n",
        "        return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScUo9pUt6OLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"mymodel.pt\", map_location=torch.device(device))\n",
        "\n",
        "# model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH_k1Q_gfNNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(model,loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _,predicted = torch.max(outputs.data,1)\n",
        "            total+=labels.size(0)\n",
        "            correct+=(predicted==labels).sum().item()\n",
        "    return (correct/total)*100, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr9cIh10fX43",
        "colab_type": "code",
        "outputId": "12b704d6-05bb-44f2-f21b-235ad05039b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "acc, data_size = calculate_accuracy(model, testloader)\n",
        "print(acc, data_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.22 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUhYB7JUJYnO",
        "colab_type": "text"
      },
      "source": [
        "### Transfer attack from pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-F61IBoJk3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_fooling_image(X, target_y, model):\n",
        "    \"\"\"\n",
        "    Generate a fooling image that is close to X, but that the model classifies\n",
        "    as target_y.\n",
        "\n",
        "    Inputs:\n",
        "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
        "    - target_y: An integer in the range [0, 1000)\n",
        "    - model: A pretrained CNN\n",
        "\n",
        "    Returns:\n",
        "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
        "    by the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Initialize our fooling image to the input image, and wrap it in a Variable.\n",
        "    X_fooling = X.clone()\n",
        "    X_fooling_var = Variable(X_fooling, requires_grad=True)\n",
        "    X_fooling_var.to(device)\n",
        "    \n",
        "    # We will fix these parameters for everyone so that there will be \n",
        "    # comparable outputs\n",
        "    \n",
        "    learning_rate = 10 # learning rate is 1\n",
        "    max_iter = 100 # maximum number of iterations\n",
        "    \n",
        "    for it in range(max_iter):\n",
        "\n",
        "    ##############################################################################\n",
        "    # Generate a fooling image X_fooling that the model will classify as   #\n",
        "    # the class target_y. You should perform gradient ascent on the score of the #\n",
        "    # target class, stopping when the model is fooled.                           #\n",
        "    # When computing an update step, first normalize the gradient:               #\n",
        "    #   dX = learning_rate * g / ||g||_2                                         #\n",
        "    #                                                                            #\n",
        "    ##############################################################################\n",
        "        check_freq = 1\n",
        "#         model.zero_grad()\n",
        "        output = model(X_fooling_var)\n",
        "        \n",
        "        score, pred = torch.max(output,dim=1) \n",
        "        \n",
        "        score_y = output[:,target_y]\n",
        "        score_y.backward()\n",
        "        \n",
        "        if it % check_freq == 0:\n",
        "            print(\"Iteration: \", it)\n",
        "            print(\"Predicted Class: {}, \\t Predicted Class Score: {}\".format(pred[0], score[0]))\n",
        "            print(\"Target Class: {}, \\t Target Class Score: {}\".format(target_y, score_y[0]))\n",
        "       \n",
        "        if pred[0] != target_y:\n",
        "            grad_x = X_fooling_var.grad\n",
        "            # Check normalization??\n",
        "            norm_grad = torch.norm(grad_x)**2\n",
        "            dx = learning_rate * grad_x / norm_grad\n",
        "            X_fooling_var.data += dx\n",
        "            X_fooling_var.grad.zero_()\n",
        "\n",
        "        else:\n",
        "            break\n",
        "        \n",
        "    ##############################################################################\n",
        "    #                             END OF YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "    \n",
        "    X_fooling = X_fooling_var.data\n",
        "    \n",
        "    return X_fooling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my_cvWjtJX63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and load the pretrained SqueezeNet model.\n",
        "proxy_model = torchvision.models.squeezenet1_1(pretrained=True)\n",
        "proxy_model = proxy_model.to(device)\n",
        "\n",
        "# We don't want to train the model, so tell PyTorch not to compute gradients\n",
        "# with respect to model parameters.\n",
        "for param in proxy_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4X5CsJLomp",
        "colab_type": "code",
        "outputId": "be9410b8-0284-451a-b1f7-ac25990a6153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "acc, data_size = calculate_accuracy(proxy_model, testloader)\n",
        "print(acc, data_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7IWkWD5Jrd_",
        "colab_type": "code",
        "outputId": "4f08d39b-5d0c-4d5a-9464-6af2d0bd2fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "idx = 0\n",
        "target_y = 6 # target label. Change to a different label to see the difference.\n",
        "\n",
        "image, label = testset[idx:idx+1]\n",
        "\n",
        "# X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
        "# X_fooling = make_fooling_image(X_tensor[idx:idx+1], target_y, model)\n",
        "\n",
        "X_fooling = make_fooling_image(image, target_y, proxy_model)\n",
        "scores = model(Variable(X_fooling))\n",
        "\n",
        "if target_y == scores.data.max(1)[1][0]: \n",
        "    print('Fooled the model!')\n",
        "else:\n",
        "    print('The model is not fooled!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2415\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'typestr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 32, 3), '|u1')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5a39d434e89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;31m# target label. Change to a different label to see the difference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# print(typekey)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1RiHmfiKJiu",
        "colab_type": "code",
        "outputId": "0c51be2a-0a77-4851-e640-0e9e8e9836d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C858wZYNmBYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_Z8w2VmF_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test( model, proxy_model, test_loader, epsilon ):\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "        # Send the data and label to the device\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "        # Forward pass the data through the model\n",
        "        \n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "            \n",
        "        proxy_output = proxy_model(data)\n",
        "        # Calculate the loss\n",
        "        loss = criterion(proxy_output, target)\n",
        "        # Zero all existing gradients\n",
        "        proxy_model.zero_grad()\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "        \n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        \n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LFeHECkmrl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXntfNPHmKlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proxy_model = CNN()\n",
        "proxy_model.load_state_dict(torch.load(\"cifar10_76\"))\n",
        "proxy_model.eval()\n",
        "proxy_model = proxy_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usUjpU7sq652",
        "colab_type": "code",
        "outputId": "596694a7-964f-4e60-8f24-9f154a3d46fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "proxy_model = torch.load(\"mymodel (1).pt\", map_location=torch.device(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oKtcYlxsRBj",
        "colab_type": "code",
        "outputId": "2ffd30ad-aff0-4d68-8842-8083e20a8e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "proxy_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  )\n",
              "  (1): mymodel(\n",
              "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAmodEYgmJXk",
        "colab_type": "code",
        "outputId": "06ce756c-b80a-444c-b1f4-b2b0774e5e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "epsilons = [0,0.05,0.1,0.15,0.2,0.25,0.3]\n",
        "# Run test for each epsilon\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, proxy_model, testloader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 2616 / 10000 = 0.2616\n",
            "Epsilon: 0.05\tTest Accuracy = 1696 / 10000 = 0.1696\n",
            "Epsilon: 0.1\tTest Accuracy = 1418 / 10000 = 0.1418\n",
            "Epsilon: 0.15\tTest Accuracy = 1192 / 10000 = 0.1192\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}